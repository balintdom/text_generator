{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "def cleaning(text):\n",
    "    # clean the text from URLs, hashtags, and stopwords\n",
    "    \n",
    "    # clear the text from punctuation\n",
    "    punct = string.punctuation.replace('\\'', '')\n",
    "    text = [word.translate(\"\".maketrans(punct, \" \"*len(punct))) for word in text.split()]\n",
    "\n",
    "    # lemmatize text\n",
    "    stemmer = WordNetLemmatizer()\n",
    "    text = [stemmer.lemmatize(word).lower() for word in text]\n",
    "    \n",
    "    sw = stopwords.words('english')\n",
    "    text = [word for word in text if word not in sw]\n",
    "    \n",
    "    # remove unecessary spaces\n",
    "    text = re.sub('\\s+', ' ', ' '.join(text).strip())\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/moliere_complete.txt', 'r') as f:\n",
    "    moliere = ''.join(list(f))\n",
    "    clean_moliere = cleaning(moliere)\n",
    "    \n",
    "dataset_moliere = [clean_moliere[i*100:(i+1)*100] for i in range(int(len(clean_moliere)/100))][:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load shakespeare db\n",
    "import tensorflow as tf\n",
    "\n",
    "path_to_file = tf.keras.utils.get_file('shakespeare.txt', \n",
    "                                       'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
    "shakespeare = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "clean_shakespeare= cleaning(shakespeare)\n",
    "dataset_shakespeare = [clean_shakespeare[i*100:(i+1)*100] for i in range(int(len(clean_shakespeare)/100))][:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "with open('./result/lstm_moliere.pkl', 'rb') as f:\n",
    "    lstm_moliere = [cleaning(i)[:100] for i in pkl.load(f)]\n",
    "    lstm_moliere = [i for i in lstm_moliere if len(i)==100]\n",
    "    \n",
    "with open('./result/lstm_shakespeare.pkl', 'rb') as f:\n",
    "    lstm_shakespeare = [cleaning(i)[:100] for i in pkl.load(f)]\n",
    "    lstm_shakespeare = [i for i in lstm_shakespeare if len(i)==100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def create_input_output(moliere, shakespeare):\n",
    "    dataset = moliere+shakespeare\n",
    "    # create labels \n",
    "    Y = np.zeros([len(dataset), 2])\n",
    "\n",
    "    Y[:len(moliere), 0] = 1\n",
    "    Y[len(shakespeare):, 1] = 1\n",
    "\n",
    "    # tokenize the text\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(char_level=True)\n",
    "    tokenizer.fit_on_texts(dataset)\n",
    "\n",
    "    # create the data matrix, truncate it to 20 length\n",
    "    x = tokenizer.texts_to_sequences(dataset)\n",
    "    X = tf.keras.preprocessing.sequence.pad_sequences(x, maxlen=100)\n",
    "    print(len(tokenizer.word_index))\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "X, Y = create_input_output(dataset_moliere, dataset_shakespeare)\n",
    "X_aug, Y_aug = create_input_output(lstm_moliere, lstm_shakespeare)\n",
    "\n",
    "# train, validation and test splits\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X, Y, test_size=0.1)\n",
    "X_train,  X_test, Y_train, Y_test = train_test_split(X_train, Y_train, test_size=0.1*(1/0.9))\n",
    "\n",
    "# X_train = np.concatenate([X_train, X_aug])\n",
    "# Y_train = np.concatenate([Y_train, Y_aug])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "150/150 [==============================] - 4s 15ms/step - loss: 0.6962 - acc: 0.5085 - val_loss: 0.6848 - val_acc: 0.5750\n",
      "Epoch 2/20\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 0.6885 - acc: 0.5578 - val_loss: 0.6371 - val_acc: 0.6483\n",
      "Epoch 3/20\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 0.5637 - acc: 0.7169 - val_loss: 0.4934 - val_acc: 0.7483\n",
      "Epoch 4/20\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 0.4782 - acc: 0.7539 - val_loss: 0.4683 - val_acc: 0.7783\n",
      "Epoch 5/20\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 0.4324 - acc: 0.8000 - val_loss: 0.4292 - val_acc: 0.7700\n",
      "Epoch 6/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.3729 - acc: 0.8354 - val_loss: 0.4177 - val_acc: 0.8000\n",
      "Epoch 7/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.3365 - acc: 0.8504 - val_loss: 0.3727 - val_acc: 0.8150\n",
      "Epoch 8/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.3178 - acc: 0.8652 - val_loss: 0.3530 - val_acc: 0.8417\n",
      "Epoch 9/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.2804 - acc: 0.8832 - val_loss: 0.4183 - val_acc: 0.8200\n",
      "Epoch 10/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.2650 - acc: 0.8875 - val_loss: 0.4075 - val_acc: 0.8400\n",
      "Epoch 11/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.2485 - acc: 0.8953 - val_loss: 0.3228 - val_acc: 0.8700\n",
      "Epoch 12/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.2212 - acc: 0.9102 - val_loss: 0.3229 - val_acc: 0.8633\n",
      "Epoch 13/20\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 0.2015 - acc: 0.9160 - val_loss: 0.3442 - val_acc: 0.8600\n",
      "Epoch 14/20\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2004 - acc: 0.920 - 2s 12ms/step - loss: 0.2003 - acc: 0.9204 - val_loss: 0.4182 - val_acc: 0.8583\n",
      "Epoch 15/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.1877 - acc: 0.9213 - val_loss: 0.3464 - val_acc: 0.8600\n",
      "Epoch 16/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.1861 - acc: 0.9218 - val_loss: 0.4149 - val_acc: 0.8700\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3059 - acc: 0.8550\n",
      "Epoch 1/20\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 0.2216 - acc: 0.9106 - val_loss: 0.3362 - val_acc: 0.8583\n",
      "Epoch 2/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.2020 - acc: 0.9142 - val_loss: 0.3960 - val_acc: 0.8533\n",
      "Epoch 3/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.1877 - acc: 0.9244 - val_loss: 0.3519 - val_acc: 0.8550\n",
      "Epoch 4/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.1681 - acc: 0.9331 - val_loss: 0.3672 - val_acc: 0.8733\n",
      "Epoch 5/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.1755 - acc: 0.9277 - val_loss: 0.3205 - val_acc: 0.8800\n",
      "Epoch 6/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.1516 - acc: 0.9396 - val_loss: 0.4137 - val_acc: 0.8783\n",
      "Epoch 7/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.1666 - acc: 0.9346 - val_loss: 0.3595 - val_acc: 0.8667\n",
      "Epoch 8/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.1462 - acc: 0.9400 - val_loss: 0.3712 - val_acc: 0.8750\n",
      "Epoch 9/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.1434 - acc: 0.9410 - val_loss: 0.3722 - val_acc: 0.8700\n",
      "Epoch 10/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.1380 - acc: 0.9458 - val_loss: 0.3435 - val_acc: 0.8650\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3022 - acc: 0.8967\n",
      "Epoch 1/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.1513 - acc: 0.9377 - val_loss: 0.3278 - val_acc: 0.8683\n",
      "Epoch 2/20\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 0.1328 - acc: 0.9446 - val_loss: 0.3408 - val_acc: 0.8717\n",
      "Epoch 3/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.1342 - acc: 0.9469 - val_loss: 0.3938 - val_acc: 0.8767\n",
      "Epoch 4/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.1217 - acc: 0.9494 - val_loss: 0.4333 - val_acc: 0.8500\n",
      "Epoch 5/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.1251 - acc: 0.9485 - val_loss: 0.3704 - val_acc: 0.8733\n",
      "Epoch 6/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.1177 - acc: 0.9550 - val_loss: 0.4115 - val_acc: 0.8650\n",
      "Epoch 7/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.1323 - acc: 0.9467 - val_loss: 0.5481 - val_acc: 0.8567\n",
      "Epoch 8/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.1408 - acc: 0.9446 - val_loss: 0.3663 - val_acc: 0.8683\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3651 - acc: 0.8717\n",
      "Epoch 1/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.1380 - acc: 0.9442 - val_loss: 0.4029 - val_acc: 0.8750\n",
      "Epoch 2/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.1163 - acc: 0.9556 - val_loss: 0.3716 - val_acc: 0.8717\n",
      "Epoch 3/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.1222 - acc: 0.9521 - val_loss: 0.3699 - val_acc: 0.8700\n",
      "Epoch 4/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.1264 - acc: 0.9479 - val_loss: 0.4292 - val_acc: 0.8850\n",
      "Epoch 5/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.1424 - acc: 0.9419 - val_loss: 0.3774 - val_acc: 0.8533\n",
      "Epoch 6/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.1259 - acc: 0.9519 - val_loss: 0.3628 - val_acc: 0.8850\n",
      "Epoch 7/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0947 - acc: 0.9625 - val_loss: 0.5087 - val_acc: 0.8867\n",
      "Epoch 8/20\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0943 - acc: 0.964 - 2s 12ms/step - loss: 0.0940 - acc: 0.9648 - val_loss: 0.4120 - val_acc: 0.8833\n",
      "Epoch 9/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.1162 - acc: 0.9575 - val_loss: 0.4679 - val_acc: 0.8783\n",
      "Epoch 10/20\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 0.1332 - acc: 0.9483 - val_loss: 0.4497 - val_acc: 0.8717\n",
      "Epoch 11/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.1284 - acc: 0.9508 - val_loss: 0.4091 - val_acc: 0.9000\n",
      "Epoch 12/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0936 - acc: 0.9621 - val_loss: 0.5120 - val_acc: 0.8600\n",
      "Epoch 13/20\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0987 - acc: 0.959 - 2s 12ms/step - loss: 0.0994 - acc: 0.9598 - val_loss: 0.4051 - val_acc: 0.8667\n",
      "Epoch 14/20\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 0.1276 - acc: 0.9473 - val_loss: 0.4285 - val_acc: 0.8783\n",
      "Epoch 15/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0977 - acc: 0.9633 - val_loss: 0.4423 - val_acc: 0.8683\n",
      "Epoch 16/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.1438 - acc: 0.9460 - val_loss: 0.3316 - val_acc: 0.8683\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4709 - acc: 0.8800\n",
      "Epoch 1/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0787 - acc: 0.9677 - val_loss: 0.5004 - val_acc: 0.8733\n",
      "Epoch 2/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0854 - acc: 0.9658 - val_loss: 0.4497 - val_acc: 0.8983\n",
      "Epoch 3/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.1010 - acc: 0.9625 - val_loss: 0.3542 - val_acc: 0.8917\n",
      "Epoch 4/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.1025 - acc: 0.9629 - val_loss: 0.4083 - val_acc: 0.8600\n",
      "Epoch 5/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.1099 - acc: 0.9596 - val_loss: 0.4333 - val_acc: 0.8767\n",
      "Epoch 6/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0798 - acc: 0.9696 - val_loss: 0.4332 - val_acc: 0.8833\n",
      "Epoch 7/20\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 0.1135 - acc: 0.9569 - val_loss: 0.3998 - val_acc: 0.9017\n",
      "Epoch 8/20\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 0.1153 - acc: 0.9554 - val_loss: 0.4382 - val_acc: 0.8567\n",
      "Epoch 9/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.1172 - acc: 0.9552 - val_loss: 0.3876 - val_acc: 0.8733\n",
      "Epoch 10/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.1280 - acc: 0.9500 - val_loss: 0.3828 - val_acc: 0.8950\n",
      "Epoch 11/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0995 - acc: 0.9604 - val_loss: 0.4965 - val_acc: 0.8817\n",
      "Epoch 12/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0846 - acc: 0.9700 - val_loss: 0.5438 - val_acc: 0.8850\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4506 - acc: 0.8650\n",
      "Epoch 1/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0910 - acc: 0.9654 - val_loss: 0.4205 - val_acc: 0.8917\n",
      "Epoch 2/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0712 - acc: 0.9698 - val_loss: 0.4533 - val_acc: 0.8700\n",
      "Epoch 3/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.1322 - acc: 0.9473 - val_loss: 0.4234 - val_acc: 0.8667\n",
      "Epoch 4/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.1526 - acc: 0.9392 - val_loss: 0.3812 - val_acc: 0.8883\n",
      "Epoch 5/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.1292 - acc: 0.9498 - val_loss: 0.4698 - val_acc: 0.8817\n",
      "Epoch 6/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.1116 - acc: 0.9556 - val_loss: 0.5319 - val_acc: 0.8667\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3818 - acc: 0.8967\n",
      "Epoch 1/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0767 - acc: 0.9735 - val_loss: 0.4263 - val_acc: 0.8733\n",
      "Epoch 2/20\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 0.0901 - acc: 0.9650 - val_loss: 0.3504 - val_acc: 0.8833\n",
      "Epoch 3/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0884 - acc: 0.9677 - val_loss: 0.4190 - val_acc: 0.8767\n",
      "Epoch 4/20\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 0.0809 - acc: 0.9688 - val_loss: 0.4050 - val_acc: 0.8817\n",
      "Epoch 5/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0831 - acc: 0.9706 - val_loss: 0.3663 - val_acc: 0.8800\n",
      "Epoch 6/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0808 - acc: 0.9694 - val_loss: 0.4859 - val_acc: 0.8800\n",
      "Epoch 7/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0840 - acc: 0.9681 - val_loss: 0.4369 - val_acc: 0.8900\n",
      "Epoch 8/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0710 - acc: 0.9723 - val_loss: 0.5399 - val_acc: 0.8600\n",
      "Epoch 9/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0922 - acc: 0.9648 - val_loss: 0.4731 - val_acc: 0.8850\n",
      "Epoch 10/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0723 - acc: 0.9746 - val_loss: 0.5264 - val_acc: 0.8667\n",
      "Epoch 11/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0976 - acc: 0.9596 - val_loss: 0.4946 - val_acc: 0.8750\n",
      "Epoch 12/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.1398 - acc: 0.9479 - val_loss: 0.4517 - val_acc: 0.8633\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4128 - acc: 0.8967\n",
      "Epoch 1/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0655 - acc: 0.9773 - val_loss: 0.4951 - val_acc: 0.8850\n",
      "Epoch 2/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0595 - acc: 0.9794 - val_loss: 0.4872 - val_acc: 0.8800\n",
      "Epoch 3/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0882 - acc: 0.9681 - val_loss: 0.4562 - val_acc: 0.8683\n",
      "Epoch 4/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0812 - acc: 0.9696 - val_loss: 0.5158 - val_acc: 0.8700\n",
      "Epoch 5/20\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 0.1034 - acc: 0.9617 - val_loss: 0.4360 - val_acc: 0.8917\n",
      "Epoch 6/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0872 - acc: 0.9679 - val_loss: 0.4656 - val_acc: 0.8633\n",
      "Epoch 7/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.1081 - acc: 0.9621 - val_loss: 0.4136 - val_acc: 0.8900\n",
      "Epoch 8/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0947 - acc: 0.9629 - val_loss: 0.4969 - val_acc: 0.8883\n",
      "Epoch 9/20\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 0.0700 - acc: 0.9754 - val_loss: 0.6578 - val_acc: 0.8583\n",
      "Epoch 10/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0859 - acc: 0.9688 - val_loss: 0.4489 - val_acc: 0.8900\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4202 - acc: 0.8850\n",
      "Epoch 1/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0840 - acc: 0.9685 - val_loss: 0.4821 - val_acc: 0.8700\n",
      "Epoch 2/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.1394 - acc: 0.9475 - val_loss: 0.5280 - val_acc: 0.8567\n",
      "Epoch 3/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.1389 - acc: 0.9513 - val_loss: 0.3882 - val_acc: 0.8700\n",
      "Epoch 4/20\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 0.0922 - acc: 0.9638 - val_loss: 0.5027 - val_acc: 0.8717\n",
      "Epoch 5/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0906 - acc: 0.9654 - val_loss: 0.4653 - val_acc: 0.8883\n",
      "Epoch 6/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.1408 - acc: 0.9492 - val_loss: 0.3531 - val_acc: 0.8767\n",
      "Epoch 7/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.1253 - acc: 0.9535 - val_loss: 0.4098 - val_acc: 0.8967\n",
      "Epoch 8/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0902 - acc: 0.9673 - val_loss: 0.5216 - val_acc: 0.8767\n",
      "Epoch 9/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0929 - acc: 0.9617 - val_loss: 0.4808 - val_acc: 0.8767\n",
      "Epoch 10/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.1264 - acc: 0.9535 - val_loss: 0.4216 - val_acc: 0.8667\n",
      "Epoch 11/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.1201 - acc: 0.9542 - val_loss: 0.4567 - val_acc: 0.8767\n",
      "Epoch 12/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.0878 - acc: 0.9681 - val_loss: 0.5357 - val_acc: 0.8767\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3920 - acc: 0.8800\n",
      "Epoch 1/20\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 0.0818 - acc: 0.9725 - val_loss: 0.4591 - val_acc: 0.8933\n",
      "Epoch 2/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.1839 - acc: 0.9317 - val_loss: 0.4007 - val_acc: 0.8683\n",
      "Epoch 3/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.1675 - acc: 0.9373 - val_loss: 0.5064 - val_acc: 0.8550\n",
      "Epoch 4/20\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 0.1246 - acc: 0.9525 - val_loss: 0.4362 - val_acc: 0.8633\n",
      "Epoch 5/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.1139 - acc: 0.9565 - val_loss: 0.4888 - val_acc: 0.8750\n",
      "Epoch 6/20\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.1065 - acc: 0.9610 - val_loss: 0.4425 - val_acc: 0.8817\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4408 - acc: 0.8767\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "vocab_size = 38\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=5, restore_best_weights=True)\n",
    "\n",
    "# create a simple LSTM model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(\n",
    "    input_dim=vocab_size+1,\n",
    "    output_dim=64,\n",
    "    trainable=True))\n",
    "\n",
    "model.add(LSTM(units=128, name='lstm_layer_1'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(units=256, activation='relu', name='dense_layer_1'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(units=2, name='output_layer', activation='softmax'))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', \n",
    "      optimizer =  optimizer,\n",
    "      metrics   =  ['acc'])\n",
    "results = []\n",
    "for i in range(10):\n",
    "    model.fit(x=X_train, y = Y_train, validation_data=(X_valid, Y_valid), epochs=20, callbacks = [callback])\n",
    "    result = model.evaluate(X_test, Y_test)\n",
    "    results.append(result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With data augmentation:\n",
    "    0.8936666548252106\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8803333282470703"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(results)/10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deep_learning]",
   "language": "python",
   "name": "conda-env-deep_learning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
